<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tutorial on Curious Joe</title>
    <link>/tags/tutorial/</link>
    <description>Recent content in Tutorial on Curious Joe</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jul 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/tutorial/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Automatically Build Data Tables from US Census Survey!</title>
      <link>/post/automatically-build-data-tables-from-us-census-survey/</link>
      <pubDate>Fri, 10 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/automatically-build-data-tables-from-us-census-survey/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#brief-background-on-us-census-surveys&#34;&gt;Brief Background on US Census Surveys&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#preparation&#34;&gt;Preparation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#getting-your-api-key&#34;&gt;Getting your API Key&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#setting-up-the-key&#34;&gt;Setting up the Key&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calling-census-api-to-get-tract-household-income&#34;&gt;Calling Census API to Get Tract Household Income&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#limitations-of-this-code&#34;&gt;Limitations of this Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#overcoming-the-limitations&#34;&gt;Overcoming the Limitations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#making-the-state-name-input-flexible&#34;&gt;Making the state name input flexible&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#adding-fall-back-capability-in-the-year-input&#34;&gt;Adding fall back capability in the year input&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#adding-a-column-for-data-and-time&#34;&gt;Adding a column for data and time&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#whats-next&#34;&gt;What’s next?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;US Census Bureau is probably the most reliable souce of demographic data on the US population. There are hundreds of use cases of the data from Us Census Bureau. In one of our recent projects we used household income data from Census as a proxy to missing actual household income data in our table.&lt;/p&gt;
&lt;p&gt;In this article, I’ll show how we got the income data from ACS5 survey using the ‘tidycensus’ package. In doing so, I’ll show how to write your own function to wrap the out of the box function to serve your customised purpose. As bonus I’ll briefly describe how you may automate this entire process so that you can run this process from a server, save the data in your database and each year automatically update the table with the new Census data.&lt;/p&gt;
&lt;div id=&#34;brief-background-on-us-census-surveys&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Brief Background on US Census Surveys&lt;/h2&gt;
&lt;p&gt;There are different types of surveys conducted by the Census Bureau. Not all of them have the same data or data at the same level based on their nature. Here you can find details about the different survey types and other details: &lt;a href=&#34;https://www.census.gov/programs-surveys.html&#34; class=&#34;uri&#34;&gt;https://www.census.gov/programs-surveys.html&lt;/a&gt;. For our purpose we needed a survey that has household income data at the most grannular geographic level. We ended up using the American Community Survey &lt;a href=&#34;https://www.census.gov/data/developers/data-sets/acs-5year.html&#34;&gt;ACS5 survey&lt;/a&gt; because this survey contains household income data at the Census &lt;a href=&#34;https://www.census.gov/content/dam/Census/data/developers/geoareaconcepts.pdf&#34;&gt;Tract&lt;/a&gt; level which is the most grannular level for which household income data is available in census.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preparation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;div id=&#34;getting-your-api-key&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Getting your API Key&lt;/h3&gt;
&lt;p&gt;For this project we have used an R package called &lt;em&gt;tidyverse&lt;/em&gt;. Behind the scene &lt;em&gt;tidycensus&lt;/em&gt; package calls the API provided by the Census Bureau. To call this API you need to have a key, which is basically is unique ID that is automatically generated against each new user by the Census Bureau. You can get a key from here: &lt;a href=&#34;https://api.census.gov/data/key_signup.html&#34; class=&#34;uri&#34;&gt;https://api.census.gov/data/key_signup.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once you have the key save it in a separte text file or an r script. So that later on we can load the file and use that key in our functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-up-the-key&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting up the Key&lt;/h3&gt;
&lt;p&gt;Once you have the API key available you need to set it up to be used by the functions from tidycensus package. You can set it up using following line of code:&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt;census_api_key(&amp;#39;YOUR_API_KEY&amp;#39;, install = FALSE, overwrite = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have all the prerequisits set to call the Census API.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;calling-census-api-to-get-tract-household-income&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calling Census API to Get Tract Household Income&lt;/h2&gt;
&lt;p&gt;Using the following line of code you can get all the tract level household income data for an entire state in the US. We are using this variable &lt;em&gt;B19013_001&lt;/em&gt; from the ACS5 survey. You can learn more about all the available variables going to this link: &lt;a href=&#34;https://api.census.gov/data/2018/acs/acs5/variables.html&#34; class=&#34;uri&#34;&gt;https://api.census.gov/data/2018/acs/acs5/variables.html&lt;/a&gt;
So to get tract level median household income in IL for the ACS5 survey of 2018 you can run the following line of code:&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt;get_acs(state = &amp;#39;IL&amp;#39;, year = 2018, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, 
                                     geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Explanation of the code&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;get_acs()&lt;/em&gt; function is used to call the API for the ACS surveys. You should read through the code description for details but here is the brief description of the parameters used in this case:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;state: abbreviated name or names of the state(s),&lt;/li&gt;
&lt;li&gt;year: for which year’s ACS survey you are looking for.&lt;/li&gt;
&lt;li&gt;geography: at which geographic level you are looking at. We are looking for &lt;em&gt;tract&lt;/em&gt; level data. Other options are county, block etc.&lt;/li&gt;
&lt;li&gt;survey: which survey you are looking for. We are looking for **ACS5* survey,&lt;/li&gt;
&lt;li&gt;show_call: setting it up as true prints the message output in the R console while the API is called. Really helpful when you put this function in production to check back reason behind in case the function fails.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations-of-this-code&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations of this Code&lt;/h2&gt;
&lt;p&gt;Our goal is to fetch that data, store the data in a database and then schedule that script to be re-run automatically every year. Using this out of the box function doesn’t serve that entire purpose because of these limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It has to have a state name as an input. We could make it dynamic so that we could use it to load all states’ data or just a selective set of states or just one state,&lt;/li&gt;
&lt;li&gt;We want to schedule this to run automatically at a specific date. But since the ACS5 survey publication date is not exactly same each year, we need to have some flexibility so that in case our desired year’s survey isn’t populated the function falls back to fetch latest available data.&lt;/li&gt;
&lt;li&gt;We would like to have a column with the date and time recorded when this data is called and store that along with other data in the database table.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the next sections I’ll walk you through writing a customised functions which will address these limitations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;overcoming-the-limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Overcoming the Limitations&lt;/h2&gt;
&lt;p&gt;Before we start to building the elaborate function, I’ll start with a basic wrapper function. And then we’ll keep adding additional argumnts to it to overcome the limitations.&lt;/p&gt;
&lt;p&gt;Here’s how R function skeleton looks like:&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt; functionName = function(input01, input2){
                  Logic
        }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You give it a name so that in future you can save the function and reuse it. Inside the function() within parentheses you include the input variable name(s). And you write the logic inside the curly braces.&lt;/p&gt;
&lt;p&gt;Now let’s write a basic function to wrap the two pieces of codes we have written earlier to get ACS data:&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt; getAcsIncome = function(names, year, KEY = &amp;#39;YOUR_KEY&amp;#39;){
        ## setting up API call key
        census_api_key(apiKey, install = FALSE, overwrite = TRUE)
        
        ## calling get_acs()
        get_acs(state = names, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, 
                                     geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
        }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have saved my API KEY in a separate script. So I have loaded the script and using the KEY from the script to get track level data for IL from 2018 ACS5 survey.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Loading libraries and key
library(tidycensus)
source(&amp;#39;KEY.R&amp;#39;)

# Wrapper function
getAcsIncome = function(names, year, KEY){
        ## setting up API call key
        census_api_key(key = API_KEY, install = FALSE, overwrite = TRUE)
        
        ## calling get_acs()
        get_acs(state = names, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, 
                                     geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
}

# Calling the function and display glimpse of result 
IL_HH_Income = getAcsIncome(names = &amp;#39;IL&amp;#39;, year = 2018, KEY = API_KEY)
head(IL_HH_Income)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   GEOID       NAME                                      variable  estimate   moe
##   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;                                     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 17001000100 Census Tract 1, Adams County, Illinois    B19013_0~    44613  6384
## 2 17001000201 Census Tract 2.01, Adams County, Illinois B19013_0~    44878  4356
## 3 17001000202 Census Tract 2.02, Adams County, Illinois B19013_0~    46964 10202
## 4 17001000400 Census Tract 4, Adams County, Illinois    B19013_0~    33750  7386
## 5 17001000500 Census Tract 5, Adams County, Illinois    B19013_0~    38526  4846
## 6 17001000600 Census Tract 6, Adams County, Illinois    B19013_0~    51491 10117&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;making-the-state-name-input-flexible&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Making the state name input flexible&lt;/h3&gt;
&lt;p&gt;Now we have a operating function, we’ll move to the next steps where we’ll add first set of arguments to it to make the state name input flexible.&lt;/p&gt;
&lt;p&gt;We’ll use a built-in constant in R namely: state.abb. It includes the 50 state name abbreviations. In our customised wrapper function we’ll add changes to address these following use cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;download all states data when input is ‘all’/‘ALL’&lt;/li&gt;
&lt;li&gt;download selected state(s) data when input is one/multiple state names in abbreviations&lt;/li&gt;
&lt;li&gt;provide an error message if provided input doesn’t match any of the above two input types&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wrapper function
getAcsIncome = function(names, year, KEY){
        ## setting up API call key
        census_api_key(key = API_KEY, install = FALSE, overwrite = TRUE)
        
        ## setting up blank array to store state names 
        stateNames = NULL
        
        # when all states are required
        if(names %in% c(&amp;#39;all&amp;#39;, &amp;#39;ALL&amp;#39;)){
          stateNames = state.abb
        } 
        
        # when specific state or states are mentioned in names
        else if(names %in% c(state.abb)){
          stateNames = names
        }
        
        # in any other cases
        else{
          print(&amp;quot;Provide a value in stateNames variable. Available options: all/ALL/any of the 50 states (abb.)&amp;quot;)
        }
  
        ## calling get_acs()
        get_acs(state = stateNames, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
}

head(getAcsIncome(names = &amp;#39;all&amp;#39;, year = 2018, KEY = API_KEY))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   GEOID       NAME                                      variable  estimate   moe
##   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;                                     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 01001020100 Census Tract 201, Autauga County, Alabama B19013_0~    58625 14777
## 2 01001020200 Census Tract 202, Autauga County, Alabama B19013_0~    43531  6053
## 3 01001020300 Census Tract 203, Autauga County, Alabama B19013_0~    51875  8744
## 4 01001020400 Census Tract 204, Autauga County, Alabama B19013_0~    54050  5166
## 5 01001020500 Census Tract 205, Autauga County, Alabama B19013_0~    72417 14919
## 6 01001020600 Census Tract 206, Autauga County, Alabama B19013_0~    46688 13043&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-fall-back-capability-in-the-year-input&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adding fall back capability in the year input&lt;/h3&gt;
&lt;p&gt;To add that capability we’ll use a package called &lt;em&gt;tryCatchLog&lt;/em&gt;. The basic sceleton of tryCatch() function that we’ll use is like following:&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt;
result = tryCatch({
    expr
}, warning = function(w) {
    warning-handler-code
}, error = function(e) {
    error-handler-code
}, finally = {
    cleanup-code
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here inside the curly braces you add the code to evaluate and inside second function, following warning/error, provide the logic to execute if the first code block fails. The above skeleton was copied from this &lt;a href=&#34;http://mazamascience.com/WorkingWithData/?p=912&#34;&gt;article&lt;/a&gt;. That article has a more detailed discussion on how to apply try catch function.&lt;/p&gt;
&lt;p&gt;In our case we’ll use trycatch function to update a variable. Then we’ll add additional code block that will run based on the value of that variable. Also if the first code block fails, we’ll print out a message where the error message will be printed starting with the date showing which year it tried.&lt;/p&gt;
&lt;p&gt;The tryCatch block of our code inside the function will look like following:&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt;
  # starting with variable: an.error.occured with value of FALSE
  an.error.occured &amp;lt;- FALSE
  tryCatch({
    
    # trying for current year - 2 
    year = as.numeric(substr(Sys.Date(), start = 1, stop = 4)) - 2
    
    # calling api to get data
    data = tidycensus::get_acs(state = name, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
    }, error = function(e) {
    
    # updating the variable
    an.error.occured &amp;lt;&amp;lt;- TRUE
    # printing out error message to be stored in log with the 
    message(paste0(&amp;quot;Year tried: &amp;quot;, year, &amp;quot;/n&amp;quot;, e))})
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the above block we are capturing if our first try of the code block fails. If it fails we are updating &lt;em&gt;an.error.occured&lt;/em&gt; variable to TRUE. Which will trigger the next block where we’ll use one year older year value.&lt;/p&gt;
&lt;p&gt;Eventually the final function with the added full trycatch functionality will look like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;getAcsIncome = function(names, year, KEY){
  
   ## setting up API call key
        census_api_key(key = API_KEY, install = FALSE, overwrite = TRUE)
        
        ## setting up blank array to store state names 
        stateNames = NULL
        
        # when all states are required
        if(names %in% c(&amp;#39;all&amp;#39;, &amp;#39;ALL&amp;#39;)){
          stateNames = state.abb
        } 
        
        # when specific state or states are mentioned in names
        else if(names %in% c(state.abb)){
          stateNames = names
        }
        
        # in any other cases
        else{
          print(&amp;quot;Provide a value in stateNames variable. Available options: all/ALL/any of the 50 states (abb.)&amp;quot;)
        }
  
  # starting with variable: an.error.occured with value of FALSE
  an.error.occured &amp;lt;- FALSE
  tryCatch({
    
    # calling api to get data
    data = tidycensus::get_acs(state = stateNames, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
    }, error = function(e) {
    
    # updating the variable
    an.error.occured &amp;lt;&amp;lt;- TRUE
    # printing out error message to be stored in log
    message(paste0(&amp;quot;Year tried: &amp;quot;, year, &amp;quot;\n&amp;quot;, e))})
  
  
  #  try for 2 year older data
  if(an.error.occured == TRUE){
    year = year - 2
    
    # calling api to get data
    data = tidycensus::get_acs(state = stateNames, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
  }
  
  ## returning resulting data
  return(data)
}

head(getAcsIncome(names = &amp;#39;IL&amp;#39;, year = 2020, KEY = API_KEY))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## To install your API key for use in future sessions, run this function with `install = TRUE`.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Getting data from the 2016-2020 5-year ACS&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Census API call: https://api.census.gov/data/2020/acs/acs5?get=B19013_001E%2CB19013_001M%2CNAME&amp;amp;for=tract%3A%2A&amp;amp;in=state%3A17&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Year tried: 2020
## Error: Your API call has errors.  The API message returned is &amp;lt;html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Error report&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;HTTP Status 404 - /data/2020/acs/acs5&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Getting data from the 2014-2018 5-year ACS&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Census API call: https://api.census.gov/data/2018/acs/acs5?get=B19013_001E%2CB19013_001M%2CNAME&amp;amp;for=tract%3A%2A&amp;amp;in=state%3A17&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   GEOID       NAME                                      variable  estimate   moe
##   &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;                                     &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 17001000100 Census Tract 1, Adams County, Illinois    B19013_0~    44613  6384
## 2 17001000201 Census Tract 2.01, Adams County, Illinois B19013_0~    44878  4356
## 3 17001000202 Census Tract 2.02, Adams County, Illinois B19013_0~    46964 10202
## 4 17001000400 Census Tract 4, Adams County, Illinois    B19013_0~    33750  7386
## 5 17001000500 Census Tract 5, Adams County, Illinois    B19013_0~    38526  4846
## 6 17001000600 Census Tract 6, Adams County, Illinois    B19013_0~    51491 10117&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Among the messages printed, this following message block shows that our code block inside the trycatch function failed. Then it fell back to 2 year’s older data. The reason is the latest survey data available in ACS5 is for 2018.&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt;## Year tried: 2020
## Error: Your API call has errors.  The API message returned is &amp;lt;html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Error report&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;HTTP Status 404 - /data/2020/acs/acs5&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we move on to adding our next argument block to overcome the final limitation, we need to make one more change. Since our eventual goal is to run this function from a server, let’s make the year input embedded inside the function.&lt;/p&gt;
&lt;p&gt;We’ll introduce a variable named &lt;em&gt;year&lt;/em&gt; inside the function with a default value of (current year - 2) value and then in the fall back we’ll update that variable to (current year - 3). Which will make sure that whenver we run the code, it’ll ask for the 2 year older data and even if that 2 year data is not available it’ll call for 3 year older data.&lt;/p&gt;
&lt;p&gt;Here’s the two lines of codes that will be added:&lt;/p&gt;
&lt;pre class=&#34;markdown&#34;&gt;&lt;code&gt;# creating year variable with default value
    year = as.numeric(substr(Sys.Date(), start = 1, stop = 4)) - 2
    
    #updating year variable
    year = as.numeric(substr(Sys.Date(), start = 1, stop = 4)) - 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see the final code chunk with that year functionality added.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;adding-a-column-for-data-and-time&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adding a column for data and time&lt;/h3&gt;
&lt;p&gt;This is the simplest part of this tutorial. Basically we’ll add Sys.time() as an additional column to the already fetched data.&lt;/p&gt;
&lt;p&gt;Here’s the final code chunk:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;getAcsIncome = function(names, KEY){
  
   ## setting up API call key
        census_api_key(key = API_KEY, install = FALSE, overwrite = TRUE)
        
        ## setting up blank array to store state names 
        stateNames = NULL
        
        # when all states are required
        if(names %in% c(&amp;#39;all&amp;#39;, &amp;#39;ALL&amp;#39;)){
          stateNames = state.abb
        } 
        
        # when specific state or states are mentioned in names
        else if(names %in% c(state.abb)){
          stateNames = names
        }
        
        # in any other cases
        else{
          print(&amp;quot;Provide a value in stateNames variable. Available options: all/ALL/any of the 50 states (abb.)&amp;quot;)
        }
  
  # starting with variable: an.error.occured with value of FALSE
  an.error.occured &amp;lt;- FALSE
  tryCatch({
    
    # creating year variable with default value
    year = as.numeric(substr(Sys.Date(), start = 1, stop = 4)) - 2
  
    # calling api to get data
    data = tidycensus::get_acs(state = stateNames, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
    }, error = function(e) {
    
    # updating the variable
    an.error.occured &amp;lt;&amp;lt;- TRUE
    # printing out error message to be stored in log
    message(paste0(&amp;quot;Year tried: &amp;quot;, year, &amp;quot;\n&amp;quot;, e))})
  
  
  #  try for 2 year older data
  if(an.error.occured == TRUE){
    
    #updating year variable
    year = as.numeric(substr(Sys.Date(), start = 1, stop = 4)) - 3
    
    # calling api to get data
    data = tidycensus::get_acs(state = stateNames, year = year, geography = &amp;#39;tract&amp;#39;, variables = &amp;#39;B19013_001&amp;#39;, geometry = FALSE, survey = &amp;#39;acs5&amp;#39;, show_call = TRUE)
  }
  
  # adding update data to a column
  data$UPDATE_DATE = Sys.time()
  
  ## returning resulting data
  return(data)
}

summary(getAcsIncome(names = &amp;#39;all&amp;#39;, KEY = API_KEY))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     GEOID               NAME             variable            estimate     
##  Length:72877       Length:72877       Length:72877       Min.   :  2499  
##  Class :character   Class :character   Class :character   1st Qu.: 42353  
##  Mode  :character   Mode  :character   Mode  :character   Median : 57099  
##                                                           Mean   : 64289  
##                                                           3rd Qu.: 78323  
##                                                           Max.   :250001  
##                                                           NA&amp;#39;s   :1013    
##       moe          UPDATE_DATE                 
##  Min.   :   550   Min.   :2020-07-10 09:03:57  
##  1st Qu.:  6051   1st Qu.:2020-07-10 09:03:57  
##  Median :  8711   Median :2020-07-10 09:03:57  
##  Mean   : 10212   Mean   :2020-07-10 09:03:57  
##  3rd Qu.: 12521   3rd Qu.:2020-07-10 09:03:57  
##  Max.   :126054   Max.   :2020-07-10 09:03:57  
##  NA&amp;#39;s   :1092&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-next&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;There are two things left now to set this script in a server to be run automatically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adding log file. Anytime you want to keep a script running from a server, you should consider adding logging capability to it. It’ll come real handy to debug in case the script fails.&lt;/li&gt;
&lt;li&gt;Automating this script. One easy way in Windows is to use windows’ task scheduler. You can take a look at my other tutorial[Automate Your Repetitive Reports!]](&lt;a href=&#34;https://curious-joe.net/post/automate-your-repetitive-reports/&#34; class=&#34;uri&#34;&gt;https://curious-joe.net/post/automate-your-repetitive-reports/&lt;/a&gt;) to know detail about how to automate a script using windows task scheduler.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;US Census Bureau is a great source of data on the US population. There are all sorts of interesting data available such as unemployment data, race related data, education related data and so on. All you need to do is to go through the documentation for the variable which I linked earler, here’s &lt;a href=&#34;https://api.census.gov/data/2018/acs/acs5/variables.html&#34;&gt;again&lt;/a&gt;. Hope this tutorial makes your census bureau data exploration journey easier and more useful in case you want to use that data continuously.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Is that Red Wine Good Enough?</title>
      <link>/post/is-the-red-wine-good-enough/</link>
      <pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/is-the-red-wine-good-enough/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-data&#34;&gt;Exploring Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-features&#34;&gt;Exploring Features&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#transforming-target-feature&#34;&gt;Transforming Target Feature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploring-predictors-visually&#34;&gt;Exploring Predictors Visually&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#checking-correlation&#34;&gt;Checking Correlation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feature-engineering&#34;&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-model&#34;&gt;Fitting Model&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#splitting-data&#34;&gt;Splitting Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fitting-model-on-training-data&#34;&gt;Fitting Model on Training Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#checking-model-performance&#34;&gt;Checking Model Performance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary-inisght&#34;&gt;Summary Inisght&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;Let’s assume that we have been hired by a winery to build a predictive model to check the qulity of their red wine. The traiditional way of wine testing is done by a human expert. Thus the process is prone to human error. The goal is to establish a process of producing an objective method of wine testing and combining that with the existing process to reduce human error.&lt;/p&gt;
&lt;p&gt;For the purpose of building the predictive model, we’ll use a dataset provided by UCI machine learning repository. We’ll try to predict wine quality based on features associated with wine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explore the data&lt;/li&gt;
&lt;li&gt;Predict the wine quality (binary classification)&lt;/li&gt;
&lt;li&gt;Explore model result&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;exploring-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exploring Data&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Loading data, libraries and primary glimpsing over data&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# libraries
library(dplyr)
library(ggplot2)
library(caTools)
library(caret)
library(GGally)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataFrame = read.csv(&amp;quot;https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv&amp;quot;, sep = &amp;#39;;&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(dataFrame)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  fixed.acidity   volatile.acidity  citric.acid    residual.sugar  
##  Min.   : 4.60   Min.   :0.1200   Min.   :0.000   Min.   : 0.900  
##  1st Qu.: 7.10   1st Qu.:0.3900   1st Qu.:0.090   1st Qu.: 1.900  
##  Median : 7.90   Median :0.5200   Median :0.260   Median : 2.200  
##  Mean   : 8.32   Mean   :0.5278   Mean   :0.271   Mean   : 2.539  
##  3rd Qu.: 9.20   3rd Qu.:0.6400   3rd Qu.:0.420   3rd Qu.: 2.600  
##  Max.   :15.90   Max.   :1.5800   Max.   :1.000   Max.   :15.500  
##    chlorides       free.sulfur.dioxide total.sulfur.dioxide    density      
##  Min.   :0.01200   Min.   : 1.00       Min.   :  6.00       Min.   :0.9901  
##  1st Qu.:0.07000   1st Qu.: 7.00       1st Qu.: 22.00       1st Qu.:0.9956  
##  Median :0.07900   Median :14.00       Median : 38.00       Median :0.9968  
##  Mean   :0.08747   Mean   :15.87       Mean   : 46.47       Mean   :0.9967  
##  3rd Qu.:0.09000   3rd Qu.:21.00       3rd Qu.: 62.00       3rd Qu.:0.9978  
##  Max.   :0.61100   Max.   :72.00       Max.   :289.00       Max.   :1.0037  
##        pH          sulphates         alcohol         quality     
##  Min.   :2.740   Min.   :0.3300   Min.   : 8.40   Min.   :3.000  
##  1st Qu.:3.210   1st Qu.:0.5500   1st Qu.: 9.50   1st Qu.:5.000  
##  Median :3.310   Median :0.6200   Median :10.20   Median :6.000  
##  Mean   :3.311   Mean   :0.6581   Mean   :10.42   Mean   :5.636  
##  3rd Qu.:3.400   3rd Qu.:0.7300   3rd Qu.:11.10   3rd Qu.:6.000  
##  Max.   :4.010   Max.   :2.0000   Max.   :14.90   Max.   :8.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the features we see ‘quality’ is our target feature. And we have total 11 features to be used as the predictors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-features&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exploring Features&lt;/h1&gt;
&lt;div id=&#34;transforming-target-feature&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Transforming Target Feature&lt;/h2&gt;
&lt;p&gt;Since we will cover talk about the classification model, we’ll convert our target feature from continuous to binary class. So that we would be able to fit one of the very widely used yet very easy classification models.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Distribution of original target feature labels&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# checking ratio of different labels in target feature
prop.table(table(dataFrame$quality))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##           3           4           5           6           7           8 
## 0.006253909 0.033145716 0.425891182 0.398999375 0.124452783 0.011257036&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataFrame = dataFrame %&amp;gt;%
  mutate(quality_bin = as.factor(ifelse(quality &amp;lt;= 5, 0,1))) %&amp;gt;%
  select(-quality)


p = round(prop.table(table(dataFrame$quality_bin))*100,2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After tranformation we have 53.47% cases classified records as good wines vs 46.53% as bad wines.&lt;/p&gt;
&lt;p&gt;We have a nice distribution of our target classes here! Which is very nice. Otherwise, we would’ve had to deal with &lt;em&gt;Data Balancing&lt;/em&gt;. Though we won’t cover that area in this tutorial, it’s a great discussion area to delve into. So some extra points for those who’ll learn about it!&lt;/p&gt;
&lt;p&gt;In short, we would like to &lt;strong&gt;have a balanced distribution of observations from different labels in our target feature&lt;/strong&gt;. Otherwise, some ML algorithms tend to overfit.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploring-predictors-visually&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exploring Predictors Visually&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Exploring acidity&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataFrame %&amp;gt;%
  ggplot(aes(x = as.factor(quality_bin), y = fixed.acidity, color = quality_bin)) +
  geom_boxplot(outlier.color = &amp;quot;darkred&amp;quot;, notch = FALSE) +
  ylab(&amp;quot;Acidity&amp;quot;) + xlab(&amp;quot;Quality (1 = good, 2 = bad)&amp;quot;) + 
  theme(legend.position = &amp;quot;none&amp;quot;, axis.title.x = element_blank()) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/viz_acidity-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We have multiple features that are continuous and can plot them similarly. Which means we’ll have to re write the code that we have just wrote in code chunk: viz_acidity again and again. In coding, we don’t want to do that. So we’ll create a function and wrap that around our code so that it can be reused in future!&lt;/p&gt;
&lt;p&gt;If it sounds too much, just stick with it. Once you see the code, it’ll make a lot more sense.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# boxplot_viz
# plots continuous feature in boxplot categorized on the quality_bin feature labels from dataFrame 
# @param feat Feature name (string) to be plotted
boxplot_viz = function(feat){

  dataFrame %&amp;gt;%
    ggplot(aes_string(x = as.factor(&amp;#39;quality_bin&amp;#39;), y = feat, color = &amp;#39;quality_bin&amp;#39;)) +
    geom_boxplot(outlier.color = &amp;quot;darkred&amp;quot;, notch = FALSE) +
    labs(title = paste0(&amp;quot;Boxplot of feature: &amp;quot;, feat)) + ylab(feat) + xlab(&amp;quot;Quality (1 = good, 2 = bad)&amp;quot;) + 
    theme(legend.position = &amp;quot;none&amp;quot;, axis.title.x = element_blank()) + 
    theme_minimal()
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boxplot_viz(&amp;#39;volatile.acidity&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for (i in names(dataFrame %&amp;gt;% select(-&amp;#39;quality_bin&amp;#39;))){
  print(boxplot_viz(i))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-4.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-5.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-6.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-7.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-8.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-9.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-10.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/unnamed-chunk-5-11.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-correlation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Checking Correlation&lt;/h2&gt;
&lt;p&gt;We can quickly check correlations among our predictors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataFrame %&amp;gt;% 
  # correlation plot 
  ggcorr(method = c(&amp;#39;complete.obs&amp;#39;,&amp;#39;pearson&amp;#39;), 
         nbreaks = 6, digits = 3, palette = &amp;quot;RdGy&amp;quot;, label = TRUE, label_size = 3, 
         label_color = &amp;quot;white&amp;quot;, label_round = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/correlation-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Highly correlated features don’t add new information to the model and blurrs the effect of individual feature on the predictor and thus makes it difficult to explain effect of individual features on target feature. This problem is called &lt;strong&gt;Multicollinearity&lt;/strong&gt;. As a general rule, we don’t want to keep features with very high correlation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What should be the threshold of correlation?&lt;/li&gt;
&lt;li&gt;How do we decide which variable to drop?&lt;/li&gt;
&lt;li&gt;Do correlated features hurt predictive accuracy?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All these are great questions and worth having a good understanding about. So again extra points for those who’ll learn about !&lt;/p&gt;
&lt;p&gt;Before making any decision based on correlation, check distribution of the feature. Unless any two features have a linear relation, correlation doesn’t mean much.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;feature-engineering&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Feature Engineering&lt;/h1&gt;
&lt;p&gt;Based on the insight gained from the data exploration, some features may need to be transformed or new features can be created. Some common feature engineering tasks are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalization and standardization of features&lt;/li&gt;
&lt;li&gt;Binning continuous features&lt;/li&gt;
&lt;li&gt;Creating composit features&lt;/li&gt;
&lt;li&gt;Creating dummy variables&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This tutorial won’t cover &lt;em&gt;feature engineering&lt;/em&gt; but it’s a great area to explore. A great data exploration followed by necessary feature engineering are the absolute necessary prerequisites before fitting any predictive model!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fitting Model&lt;/h1&gt;
&lt;div id=&#34;splitting-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Splitting Data&lt;/h2&gt;
&lt;p&gt;In practical world we train our predictive models on historical data which is called &lt;strong&gt;Training Data&lt;/strong&gt;. Then we apply that model on new unseen data, called &lt;strong&gt;Test Data&lt;/strong&gt;, and measure the performance. thus we can be sure that our model is stable or not over fitted on training data. But since we won’t have access to new wine data, we’ll split our dataset into training and testing data on a 80:20 ratio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(123)
split = sample.split(dataFrame$quality_bin, SplitRatio = 0.80)
training_set = subset(dataFrame, split == TRUE)
test_set = subset(dataFrame, split == FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s check the data balance in training and test data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop.table(table(training_set$quality_bin))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##         0         1 
## 0.4652072 0.5347928&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop.table(table(test_set$quality_bin))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##        0        1 
## 0.465625 0.534375&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-model-on-training-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting Model on Training Data&lt;/h2&gt;
&lt;p&gt;We’ll fit &lt;strong&gt;Logistic Regression&lt;/strong&gt; classification model on our dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_log = glm(quality_bin ~ ., 
                data = training_set, family = &amp;#39;binomial&amp;#39;)
summary(model_log)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = quality_bin ~ ., family = &amp;quot;binomial&amp;quot;, data = training_set)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.3688  -0.8309   0.2989   0.8109   2.4184  
## 
## Coefficients:
##                        Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)           17.369521  90.765368   0.191  0.84824    
## fixed.acidity          0.069510   0.112062   0.620  0.53507    
## volatile.acidity      -3.602258   0.558889  -6.445 1.15e-10 ***
## citric.acid           -1.543276   0.638161  -2.418  0.01559 *  
## residual.sugar         0.012106   0.060364   0.201  0.84106    
## chlorides             -4.291590   1.758614  -2.440  0.01467 *  
## free.sulfur.dioxide    0.027452   0.009293   2.954  0.00314 ** 
## total.sulfur.dioxide  -0.016723   0.003229  -5.180 2.22e-07 ***
## density              -23.425390  92.700349  -0.253  0.80050    
## pH                    -0.977906   0.828710  -1.180  0.23799    
## sulphates              3.070254   0.532655   5.764 8.21e-09 ***
## alcohol                0.946654   0.120027   7.887 3.10e-15 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1766.9  on 1278  degrees of freedom
## Residual deviance: 1301.4  on 1267  degrees of freedom
## AIC: 1325.4
## 
## Number of Fisher Scoring iterations: 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s plot the variables with the lowest p values/highest absolute z value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p = varImp(model_log) %&amp;gt;% data.frame() 
p = p %&amp;gt;% mutate(Features = rownames(p)) %&amp;gt;% arrange(desc(Overall)) %&amp;gt;% mutate(Features = tolower(Features))

p %&amp;gt;% ggplot(aes(x = reorder(Features, Overall), y = Overall)) + geom_col(width = .50, fill = &amp;#39;darkred&amp;#39;) + coord_flip() + 
  labs(title = &amp;quot;Importance of Features&amp;quot;, subtitle = &amp;quot;Based on the value of individual z score&amp;quot;) +
  xlab(&amp;quot;Features&amp;quot;) + ylab(&amp;quot;Abs. Z Score&amp;quot;) + 
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-09-20-is-the-red-wine-good-enough_files/figure-html/featImp-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;checking-model-performance&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Checking Model Performance&lt;/h1&gt;
&lt;p&gt;We’ll check how our model performs by running it on our previously unseen test data. We’ll compare the predicted outcome with the actual outcome and calculate some typically used binary classification model performance measuring metrics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# predict target feature in test data
y_pred = as.data.frame(predict(model_log, type = &amp;quot;response&amp;quot;, newdata = test_set)) %&amp;gt;% 
  structure( names = c(&amp;quot;pred_prob&amp;quot;)) %&amp;gt;%
  mutate(pred_cat = as.factor(ifelse(pred_prob &amp;gt; 0.5, &amp;quot;1&amp;quot;, &amp;quot;0&amp;quot;))) %&amp;gt;% 
  mutate(actual_cat = test_set$quality_bin)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p = confusionMatrix(y_pred$pred_cat, y_pred$actual_cat, positive = &amp;quot;1&amp;quot;)
p&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 108  46
##          1  41 125
##                                           
##                Accuracy : 0.7281          
##                  95% CI : (0.6758, 0.7761)
##     No Information Rate : 0.5344          
##     P-Value [Acc &amp;gt; NIR] : 9.137e-13       
##                                           
##                   Kappa : 0.4548          
##                                           
##  Mcnemar&amp;#39;s Test P-Value : 0.668           
##                                           
##             Sensitivity : 0.7310          
##             Specificity : 0.7248          
##          Pos Pred Value : 0.7530          
##          Neg Pred Value : 0.7013          
##              Prevalence : 0.5344          
##          Detection Rate : 0.3906          
##    Detection Prevalence : 0.5188          
##       Balanced Accuracy : 0.7279          
##                                           
##        &amp;#39;Positive&amp;#39; Class : 1               
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;font color = maroon&gt;&lt;strong&gt;Model Perfomance Summary:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;: 72.81% of the wine samples have been classified correctly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sensitivity/Recall&lt;/strong&gt;: 73.1% of the actual good wine samples have been classified correctly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pos Pred Value/Precision&lt;/strong&gt;: 75.3% of the total good wine predictions are actually good wines. &lt;/font&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-inisght&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Summary Inisght&lt;/h1&gt;
&lt;p&gt;So let’s summarize about what we have learned about wine testing from our exercise:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alchohol content, Volatile Acidity, Sulphate and total Sulpher Dioxide are the top four most statistically significant features that affect wine quality.&lt;/li&gt;
&lt;li&gt;Given the information about the 11 features that we have analyzed, we can accurately predict wine quality in about 73% of the cases,&lt;/li&gt;
&lt;li&gt;Which is about 26% more accurate than the accuracy achieved by using traditional expert based method.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;a href=&#34;https://www.theguardian.com/lifeandstyle/2013/jun/23/wine-tasting-junk-science-analysis&#34;&gt;“People could tell the difference between wines under £5 and those above £10 only 53% of the time for whites and only 47% of the time for reds.”&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;center&gt;
&lt;div&gt;
&lt;p&gt;&lt;img src=&#34;https://media1.tenor.com/images/f050405657f9ac48d3b976051436e885/tenor.gif?itemid=10577278&#34; width=&#34;400&#34;/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;div class=&#34;tocify-extend-page&#34; data-unique=&#34;tocify-extend-page&#34; style=&#34;height: 0;&#34;&gt;

&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Automate Your Repetitive Reports!</title>
      <link>/post/automate-your-repetitive-reports/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/automate-your-repetitive-reports/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#what-is-r-script-automation-and-why&#34;&gt;What is R script automation and why?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#outline-of-what-well-do-here&#34;&gt;Outline of what we’ll do here&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#part01-creating-the-report&#34;&gt;Part01: Creating the report:&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part02-automating-the-report-reproduction&#34;&gt;Part02: Automating the report reproduction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;what-is-r-script-automation-and-why&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is R script automation and why?&lt;/h2&gt;
&lt;p&gt;In most use cases R is used to analyze data, run statistical tests and build model. In doing so, data scientists constantly interact with R by writing codes and produce results from these interactions. Eventually, these results are stored, shared or presented as a report. But what if you have to reproduce the report every day or in other type of regular interval? Well, you can always pull up the R script and re-run the script. But wouldn’t it be nicer if it would be done automatically without you being in the middle to initiate R and running the script?&lt;/p&gt;
&lt;p&gt;In this article we’ll know how to do exactly that!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;outline-of-what-well-do-here&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Outline of what we’ll do here&lt;/h2&gt;
&lt;p&gt;Broady, this article has two sections:&lt;/p&gt;
&lt;p&gt;Firstly, in this article we’ll create a report that uses a live data, meaning a data source that gets updated in regular interval.&lt;/p&gt;
&lt;p&gt;Secondly, once the report is created, we’ll automate the process of recreating the report daily to capture the updated data.&lt;/p&gt;
&lt;div id=&#34;part01-creating-the-report&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part01: Creating the report:&lt;/h3&gt;
&lt;p&gt;Since the goal of this article is to automate the reproduction of an already built report, I have created a report already and posted here: &lt;a href=&#34;http://rpubs.com/arafath/CRAN_Report&#34; class=&#34;uri&#34;&gt;http://rpubs.com/arafath/CRAN_Report&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Feel free to go to that report and recreate it in your work station. You can name the RMarkdown script same as mine (&lt;em&gt;‘CRAN_Download_Report.Rmd’&lt;/em&gt;) and save it in the same location where you want to have your &lt;em&gt;.bat&lt;/em&gt; file and other outputs stored.&lt;/p&gt;
&lt;p&gt;What is done in that report looks like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Calling API from The Comprehensive R Archive Network (CRAN) to download daily and weekly download count of packages,&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Loading the data in R,&lt;/li&gt;
&lt;li&gt;Calculating some basic statistics e.g. counts,&lt;/li&gt;
&lt;li&gt;Visualizing the data&lt;/li&gt;
&lt;li&gt;Generating a report (html format) with the basic stats and visuals.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Data used:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CRAN has an API calling which we can get the total number of times any package is downloaded during a specific time. We’ll use the package called &lt;em&gt;cranlogs&lt;/em&gt; to call the api.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part02-automating-the-report-reproduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Part02: Automating the report reproduction&lt;/h3&gt;
&lt;p&gt;Once we have a working R script that produces result that we want, the reproduction workflow looks like as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Open up R console or some IDE&lt;/li&gt;
&lt;li&gt;Load the required R script&lt;/li&gt;
&lt;li&gt;Run the script to produce the result&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this step we’ll know how to tell R to do all these above steps &lt;strong&gt;automatically&lt;/strong&gt;. In doing so R will also complete all the steps mentioned in Part01 too.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does the automation work:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To automate rerunning the R script we will use Windows Task Scheduler (WTS). Using task scheduler a user can ask windows to execute a batch file (.bat) at a regular interval. A batch file contains a series of commands that can be executed by the command line interpreter.&lt;/p&gt;
&lt;p&gt;We will create a batch file that will run an R script automatically on daily basis. Inside that R script, it’s instructed to call the .Rmd file which creates the report.&lt;/p&gt;
&lt;p&gt;
 
&lt;/p&gt;
&lt;div id=&#34;creating-the-r-script-to-run-the-.rmd-file&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Creating the R script to run the .Rmd file&lt;/h4&gt;
&lt;p&gt;You can copy and paste the following codes in a R script and save it as &lt;em&gt;run.R&lt;/em&gt; (my r script file name):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Loading libraries [install the libraries before if not already installed]
library(knitr)
library(rmarkdown)
library(mailR)

# Knits rmd file (.Rmd is saved in the working directory)
knit(&amp;#39;CRAN_Download_Report.Rmd&amp;#39;)

# Creates the html output
render(&amp;quot;CRAN_Download_Report.md&amp;quot;)

# sending email notification
send.mail(from = &amp;quot;youremail@gmail.com&amp;quot;,
      to = c(&amp;quot;testemail@gmail.com&amp;quot;),
      cc = &amp;#39;youremail@gmail.com&amp;#39;,
      replyTo = c(&amp;quot;Reply to someone else &amp;lt;youremail@gmail.com&amp;gt;&amp;quot;),
      subject = &amp;quot;Report update status&amp;quot;,
      body = &amp;quot;Daily report on CRAN package download is updated!&amp;quot;,
      smtp = list(host.name = &amp;quot;smtp.gmail.com&amp;quot;, port = 587, user.name = &amp;quot;youremail&amp;quot;, passwd =    &amp;quot;password&amp;quot;, tls = TRUE),
      authenticate = TRUE,
      send = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What this R script does is basically kniting the rmd file and generate a html report, save it in the working directory and send an email notification.&lt;/p&gt;
&lt;p&gt;
 
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;running-r-from-windows-command-shell&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Running R from Window’s command shell&lt;/h4&gt;
&lt;p&gt;Before creating the batch file, we can run our R script from command terminal manually and check if it runs as expected.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Setting up directory&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Open the windows command shell. Search for ‘cmd’ or ‘command prompt’ in the windows and open it. It will open the black command shell.&lt;/p&gt;
&lt;p&gt;Now change the command directory to your desired location using ‘cd’ command followed by your desired file location (ref: image01).&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/cmd_cd.png&#34; width=&#34;800&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;image01&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
 
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Running R from command line&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The structure of the command that we’ll use is like this:
&amp;lt;R.exe location&amp;gt; CMD BATCH &amp;lt;.R file location&amp;gt; &lt;file saving location&gt;&lt;/p&gt;
&lt;p&gt;Here,&lt;br /&gt;
- &lt;em&gt;R.exe location&lt;/em&gt; is the file location where your R executible file is located. Executing this file should open up the R console.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;.R file location&lt;/em&gt; is the file location where you have saved your r script which will call the .Rmd file.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;file saving location&lt;/em&gt; is the location where you want to save your execution output.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For similiplicity, I’m using the same file location as my R working directory and location to save any outputs.&lt;/p&gt;
&lt;p&gt;These are the exact locations in my case:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R.exe location = &amp;quot;C:\Program Files\R\R-3.6.1\bin\x64\R.exe&amp;quot; 
.R file location = &amp;quot;C:\Users\ahossa1\Personal\Learning\Automating R Script\run.R&amp;quot; 
file saving location = &amp;quot;C:\Users\ahossa1\Personal\Learning\Automating R Script\test.Rout&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the final line of code in my computer (ref: image02):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;quot;C:\Program Files\R\R-3.6.1\bin\x64\R.exe&amp;quot; CMD BATCH &amp;quot;C:\Users\ahossa1\Personal\Learning\Projects\Automating R Script\run.R&amp;quot; &amp;quot;C:\Users\ahossa1\Personal\Learning\Projects\Automating R Script\CRAN.Rout&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/cmd_batch.png&#34; title=&#34;fig:&#34; width=&#34;800&#34; alt=&#34;image02&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;Once you enter the command (image02) and execute it, it should run the R script, which will knit rmarkdown document and save the report. You should also receive an email with the notification!&lt;/p&gt;
&lt;p&gt;
 
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-a-batch-file-with-the-command-line-instructions&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Creating a batch file with the command line instructions&lt;/h4&gt;
&lt;p&gt;We can save the command line instructions (image02) as a .bat file and save it. Then, any time we’ll need to re-create the report we can execute the .bat file and it’ll automatically call upon command line interface and execute the R script.&lt;/p&gt;
&lt;p&gt;To do that, open a text file (.txt). Paste the Windows shell commands in the .txt file and save it with an extension of &lt;em&gt;.bat&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In my computer I have named it &lt;em&gt;‘run.bat’&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;font color = maroon&gt;&lt;strong&gt;In cases where you don’t need to re-create a report on regular interval, you can just use this .bat file. All you’ll have to do is to double click (or single click) the .bat file and the report will be generated with the updated data.&lt;/strong&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;
 
&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;automating-command-line-activities-using-windows-task-scheduler&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Automating command line activities using Windows Task Scheduler&lt;/h4&gt;
&lt;p&gt;Now we’ll ask our computer to automatically call the .bat file in regular interval.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In Windows search bar search for ‘Task Schduler’ and open the app. Below how it looks like in my computer&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/taskScheduler.png&#34; title=&#34;fig:&#34; width=&#34;800&#34; alt=&#34;image03&#34; /&gt;
&lt;/center&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Select &lt;em&gt;Create Basic Task&lt;/em&gt; (red marked on image03).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Give the task a name&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/tsName.png&#34; title=&#34;fig:&#34; width=&#34;800&#34; alt=&#34;image04&#34; /&gt;
&lt;/center&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Go next and select a trigger. I selected &lt;em&gt;Daily&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt;
image05
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/tsInterval.png&#34; width=&#34;800&#34; alt=&#34;image05&#34; /&gt;
&lt;/center&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Go next and select start time.&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/tsStart.png&#34; title=&#34;fig:&#34; width=&#34;800&#34; alt=&#34;image06&#34; /&gt;
&lt;/center&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Go next and select &lt;em&gt;Start a program&lt;/em&gt; as the action.&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/tsEnd.png&#34; title=&#34;fig:&#34; width=&#34;800&#34; alt=&#34;image07&#34; /&gt;
&lt;/center&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Go next and load the program/script (.bat file).&lt;/li&gt;
&lt;/ol&gt;
&lt;center&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/tsBat.png&#34; title=&#34;fig:&#34; width=&#34;800&#34; alt=&#34;image08&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;
 
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Voilà!!&lt;/strong&gt; We are done!&lt;/p&gt;
&lt;p&gt;Now every day at 3.30pm. the report below with CRAN package downloads will be created and an email notification will be sent!&lt;/p&gt;
&lt;center&gt;
&lt;img src=&#34;/post/2020-06-23-automate-your-repetitive-reports_files/output.png&#34; width=&#34;800&#34; /&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
